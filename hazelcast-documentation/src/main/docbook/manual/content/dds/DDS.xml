<?xml version='1.0' encoding='UTF-8'?>

<!--
  ~ Copyright (c) 2008-2013, Hazelcast, Inc. All Rights Reserved.
  ~
  ~ Licensed under the Apache License, Version 2.0 (the "License");
  ~ you may not use this file except in compliance with the License.
  ~ You may obtain a copy of the License at
  ~
  ~ http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<para version="5.0" xmlns="http://docbook.org/ns/docbook"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd
      http://www.w3.org/1999/xlink http://www.w3.org/1999/xlink.xsd">
    Common Features of all Hazelcast Data Structures:
    <itemizedlist>
        <listitem>
            <para>Data in the cluster is almost evenly distributed (partitioned) across all nodes.
                So each node carries ~ (1/n
                <literal>*</literal>
                total-data) + backups , n being the
                number of nodes in the cluster.
            </para>
        </listitem>
        <listitem>
            <para>If a member goes down, its backup replica that also holds the same data, will
                dynamically redistribute the data including the ownership and locks on them to
                remaining live nodes. As a result, no data will get lost.
            </para>
        </listitem>
        <listitem>
            <para>When a new node joins the cluster, new node takes ownership(responsibility) and
                load of -some- of the entire data in the cluster. Eventually the new node will carry
                almost (1/n
                <literal>*</literal>
                total-data) + backups and becomes the new partition
                reducing the load on others.
            </para>
        </listitem>
        <listitem>
            <para>There is no single cluster master or something that can cause single point of
                failure. Every node in the cluster has equal rights and responsibilities. No-one is
                superior. And no dependency on external 'server' or 'master' kind of concept.
            </para>
        </listitem>
    </itemizedlist>
    Here is how you can retrieve existing data structure instances (map, queue, set,
    lock, topic, etc.) and how you can listen for instance events to get notified when an instance
    is created or destroyed.
    <programlisting language="java"><![CDATA[import java.util.Collection;
import com.hazelcast.config.Config;
import com.hazelcast.core.*;

public class Sample implements InstanceListener {
    public static void main(String[] args) {
        Sample sample = new Sample();

        Config cfg = new Config();
        HazelcastInstance hz = Hazelcast.newHazelcastInstance(cfg);
        hz.addInstanceListener(sample);

        Collection<Instance> instances = hz.getInstances();
        for (Instance instance : instances) {
            System.out.println(instance.getInstanceType() + "," + instance.getId());
        }
    }

    public void instanceCreated(InstanceEvent event) {
        Instance instance = event.getInstance();
        System.out.println("Created " + instance.getInstanceType() + "," + instance.getId());
    }

    public void instanceDestroyed(InstanceEvent event) {
        Instance instance = event.getInstance();
        System.out.println("Destroyed " + instance.getInstanceType() + "," + instance.getId());
    }
}]]></programlisting>
</para>
